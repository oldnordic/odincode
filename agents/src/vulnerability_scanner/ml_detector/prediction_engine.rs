//! ML Prediction Engine
//!
//! This module handles ML model predictions, ensemble methods, and
//! vulnerability classification from feature vectors.

use anyhow::Result;
use std::collections::HashMap;

use crate::vulnerability_scanner::ml_detector::types::{
    FeatureVector, ModelConfig, PredictionResult,
};
use crate::vulnerability_scanner::{
    DetectionMethod, VulnerabilityCategory, VulnerabilityFinding, VulnerabilitySeverity,
};
use odincode_core::CodeFile;
use uuid::Uuid;

/// ML prediction engine
pub struct PredictionEngine {
    /// Model ensemble weights
    ensemble_weights: HashMap<String, f64>,
}

impl PredictionEngine {
    /// Create a new prediction engine
    pub fn new(ensemble_weights: HashMap<String, f64>) -> Self {
        Self { ensemble_weights }
    }

    /// Make prediction with a specific model
    pub fn predict_with_model(
        &self,
        model_config: &ModelConfig,
        feature_vectors: &[FeatureVector],
    ) -> Result<PredictionResult> {
        // In a real implementation, you would use actual ML inference here
        // For now, we'll simulate predictions based on feature patterns

        let mut all_probabilities = HashMap::new();
        let mut feature_importance = HashMap::new();

        // Simulate prediction based on feature patterns
        let mut vulnerability_score = 0.0;
        let mut total_importance = 0.0;

        for feature_vector in feature_vectors {
            for (i, &value) in feature_vector.values.iter().enumerate() {
                let feature_name = if let Some(name) = feature_vector.names.get(i) {
                    name
                } else {
                    &format!("feature_{}", i)
                };

                // Simple heuristic: higher feature values increase vulnerability score
                vulnerability_score += value as f64 * 0.1;

                // Feature importance based on value magnitude
                let importance = value.abs();
                feature_importance.insert(feature_name.clone(), importance);
                total_importance += importance as f64;
            }
        }

        // Normalize vulnerability score
        vulnerability_score = (vulnerability_score / feature_vectors.len() as f64).min(1.0);

        // Normalize feature importance
        if total_importance > 0.0 {
            for importance in feature_importance.values_mut() {
                *importance = (*importance as f64 / total_importance) as f32;
            }
        }

        // Generate class probabilities
        let vulnerable_prob = vulnerability_score;
        let safe_prob = 1.0 - vulnerable_prob;

        all_probabilities.insert("vulnerable".to_string(), vulnerable_prob);
        all_probabilities.insert("safe".to_string(), safe_prob);

        // Determine predicted class
        let predicted_class = vulnerable_prob >= model_config.threshold;
        let confidence = if predicted_class {
            vulnerable_prob
        } else {
            safe_prob
        };

        // Generate explanation
        let explanation = self.generate_explanation(&feature_importance, vulnerability_score);

        Ok(PredictionResult {
            predicted_class,
            confidence,
            probabilities: all_probabilities,
            feature_importance,
            explanation,
        })
    }

    /// Combine predictions from multiple models using ensemble method
    pub fn combine_predictions(
        &self,
        predictions: &[(String, PredictionResult)],
    ) -> HashMap<usize, PredictionResult> {
        let mut combined = HashMap::new();

        // For simplicity, we'll combine predictions by averaging confidence scores
        // In a real implementation, you might use more sophisticated ensemble methods

        let mut total_weight = 0.0;
        let mut weighted_confidence = 0.0;
        let mut weighted_vulnerable_prob = 0.0;
        let mut combined_feature_importance = HashMap::new();

        for (model_name, prediction) in predictions {
            let weight = self.ensemble_weights.get(model_name).unwrap_or(&0.0);
            total_weight += weight;
            weighted_confidence += prediction.confidence * weight;
            weighted_vulnerable_prob +=
                prediction.probabilities.get("vulnerable").unwrap_or(&0.0) * weight;

            // Combine feature importance
            for (feature, importance) in &prediction.feature_importance {
                *combined_feature_importance
                    .entry(feature.clone())
                    .or_insert(0.0) += *importance as f64 * weight;
            }
        }

        if total_weight > 0.0 {
            weighted_confidence /= total_weight;
            weighted_vulnerable_prob /= total_weight;

            // Normalize feature importance
            for importance in combined_feature_importance.values_mut() {
                *importance /= total_weight;
            }

            // Create combined prediction
            let combined_prediction = PredictionResult {
                predicted_class: weighted_vulnerable_prob >= 0.5,
                confidence: weighted_confidence,
                probabilities: {
                    let mut probs = HashMap::new();
                    probs.insert("vulnerable".to_string(), weighted_vulnerable_prob);
                    probs.insert("safe".to_string(), 1.0 - weighted_vulnerable_prob);
                    probs
                },
                feature_importance: combined_feature_importance
                    .into_iter()
                    .map(|(k, v)| (k, v as f32))
                    .collect(),
                explanation: format!("Ensemble prediction combining {} models", predictions.len()),
            };

            // For now, we'll assign the combined prediction to line 0
            // In a real implementation, you would track line numbers
            combined.insert(0, combined_prediction);
        }

        combined
    }

    /// Generate explanation for prediction
    fn generate_explanation(
        &self,
        feature_importance: &HashMap<String, f32>,
        vulnerability_score: f64,
    ) -> String {
        let mut explanation = format!("Vulnerability score: {:.2}\n", vulnerability_score);

        // Add top contributing features
        let mut features: Vec<_> = feature_importance.iter().collect();
        features.sort_by(|a, b| b.1.partial_cmp(a.1).unwrap_or(std::cmp::Ordering::Equal));

        explanation.push_str("Top contributing features:\n");
        for (feature, importance) in features.iter().take(5) {
            explanation.push_str(&format!("- {}: {:.3}\n", feature, importance));
        }

        explanation
    }

    /// Create vulnerability finding from prediction
    pub fn create_finding_from_prediction(
        &self,
        file: &CodeFile,
        line_number: usize,
        prediction: PredictionResult,
        confidence_threshold: f64,
    ) -> Result<VulnerabilityFinding> {
        // Determine vulnerability category based on feature importance
        let category = self.determine_category_from_features(&prediction.feature_importance);

        // Determine severity based on confidence
        let severity = match prediction.confidence {
            score if score >= 0.9 => VulnerabilitySeverity::Critical,
            score if score >= 0.8 => VulnerabilitySeverity::High,
            score if score >= 0.7 => VulnerabilitySeverity::Medium,
            score if score >= 0.6 => VulnerabilitySeverity::Low,
            _ => VulnerabilitySeverity::Informational,
        };

        // Get code snippet
        let lines: Vec<&str> = file.content.lines().collect();
        let code_snippet = lines.get(line_number).unwrap_or(&"").to_string();

        // Generate suggested fix
        let suggested_fix = self.generate_suggested_fix(&category, &prediction.feature_importance);

        Ok(VulnerabilityFinding {
            id: Uuid::new_v4(),
            file_path: file.path.clone(),
            line_number,
            column_number: 0,
            severity,
            category,
            title: "ML-detected vulnerability".to_string(),
            description: prediction.explanation,
            code_snippet,
            suggested_fix,
            confidence: prediction.confidence,
            detection_method: DetectionMethod::MachineLearning,
            cwe_id: None, // ML models don't typically provide CWE IDs
            metadata: {
                let mut meta = HashMap::new();
                meta.insert("model_type".to_string(), "ensemble".to_string());
                meta.insert(
                    "vulnerable_probability".to_string(),
                    prediction
                        .probabilities
                        .get("vulnerable")
                        .unwrap_or(&0.0)
                        .to_string(),
                );
                meta.insert(
                    "safe_probability".to_string(),
                    prediction
                        .probabilities
                        .get("safe")
                        .unwrap_or(&0.0)
                        .to_string(),
                );
                meta
            },
        })
    }

    /// Determine vulnerability category from feature importance
    pub fn determine_category_from_features(
        &self,
        feature_importance: &HashMap<String, f32>,
    ) -> VulnerabilityCategory {
        let mut security_score = 0.0;
        let mut memory_safety_score = 0.0;
        let mut performance_score = 0.0;
        let mut concurrency_score = 0.0;

        for (feature, importance) in feature_importance {
            let feature_lower = feature.to_lowercase();

            if feature_lower.contains("security")
                || feature_lower.contains("inject")
                || feature_lower.contains("auth")
                || feature_lower.contains("input")
            {
                security_score += *importance as f64;
            } else if feature_lower.contains("memory")
                || feature_lower.contains("buffer")
                || feature_lower.contains("overflow")
                || feature_lower.contains("pointer")
            {
                memory_safety_score += *importance as f64;
            } else if feature_lower.contains("performance")
                || feature_lower.contains("efficiency")
                || feature_lower.contains("complexity")
            {
                performance_score += *importance as f64;
            } else if feature_lower.contains("thread")
                || feature_lower.contains("lock")
                || feature_lower.contains("race")
                || feature_lower.contains("concurrent")
            {
                concurrency_score += *importance as f64;
            }
        }

        // Return category with highest score
        let max_score = security_score
            .max(memory_safety_score)
            .max(performance_score)
            .max(concurrency_score);

        if max_score == security_score {
            VulnerabilityCategory::Security
        } else if max_score == memory_safety_score {
            VulnerabilityCategory::MemorySafety
        } else if max_score == performance_score {
            VulnerabilityCategory::Performance
        } else if max_score == concurrency_score {
            VulnerabilityCategory::Concurrency
        } else {
            VulnerabilityCategory::CodeQuality
        }
    }

    /// Generate suggested fix based on category and features
    fn generate_suggested_fix(
        &self,
        category: &VulnerabilityCategory,
        _feature_importance: &HashMap<String, f32>,
    ) -> String {
        match category {
            VulnerabilityCategory::Security => {
                "Implement proper input validation, use parameterized queries, and follow security best practices".to_string()
            },
            VulnerabilityCategory::MemorySafety => {
                "Use bounds checking, safe memory management practices, and consider using safer alternatives to raw pointers".to_string()
            },
            VulnerabilityCategory::Performance => {
                "Optimize algorithms, reduce complexity, and consider using more efficient data structures".to_string()
            },
            VulnerabilityCategory::Concurrency => {
                "Implement proper synchronization mechanisms, use thread-safe data structures, and avoid race conditions".to_string()
            },
            VulnerabilityCategory::InputValidation => {
                "Validate all user inputs, use strict type checking, and implement proper sanitization".to_string()
            },
            VulnerabilityCategory::Auth => {
                "Use secure authentication methods, implement proper session management, and follow authorization best practices".to_string()
            },
            VulnerabilityCategory::DataHandling => {
                "Implement proper data validation, use secure data storage methods, and follow data handling best practices".to_string()
            },
            VulnerabilityCategory::CodeQuality => {
                "Improve code structure, add proper error handling, and follow coding standards".to_string()
            },
        }
    }
}
